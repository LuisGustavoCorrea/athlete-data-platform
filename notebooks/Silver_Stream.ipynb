{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d67c098-2392-439f-800b-e99c95771b2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window\n",
    "from delta.tables import DeltaTable\n",
    "from py_functions_silver import *\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "from dataquality_rules_strava import get_rules_activity\n",
    "\n",
    "\n",
    "BRONZE = \"uc_athlete_data.bronze.strava_activities\"\n",
    "CHECKPOINT = \"abfss://silver@adlsathlete.dfs.core.windows.net/strava/activities/activities_checkpoint/\"\n",
    "\n",
    "# chave(s) de negócio — mude p/ composto se precisar, ex.: [\"activity_id\",\"lap_index\"]\n",
    "BUSINESS_KEYS = [\"athlete_id\",\"id\"]\n",
    "# colunas de ordenação para decidir o “vencedor” nos duplicados do micro-lote\n",
    "ORDER_COLS = [\"ingestion_timestamp\"]  # adicione \"updated_at\" se existir\n",
    "\n",
    "config = get_rules_activity()\n",
    "rules = config[\"rules\"]\n",
    "reject_table = config[\"reject_table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c3c2b1-d7ab-4990-8b8d-690c0d2a8008",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Compose (aplica tudo que você mostrou) -----------------------------------\n",
    "\n",
    "def apply_all_silver_calcs(df: DataFrame,\n",
    "                           *,\n",
    "                           type_col: str = \"type\",\n",
    "                           distance_col: str = \"distance\",\n",
    "                           average_speed_col: str = \"average_speed\",\n",
    "                           moving_time_col: str = \"moving_time\",\n",
    "                           elapsed_time_col: str = \"elapsed_time\",\n",
    "                           start_date_col: str = \"start_date\",\n",
    "                           non_run_value_for_pace=0  # para manter igual ao seu snippet\n",
    "                           ) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Aplica TODAS as transformações do snippet original.\n",
    "    Retorna um novo DataFrame com:\n",
    "      - start_date (date)\n",
    "      - distance_km\n",
    "      - average_speed_kmh\n",
    "      - pace_min_km\n",
    "      - pace_min_km_moving_time\n",
    "      - tempo_real (HH:MM:SS)\n",
    "      - pace_min_km_new\n",
    "      - pace_strava (M:SS)\n",
    "      - dia_semana\n",
    "    \"\"\"\n",
    "    return (\n",
    "        df\n",
    "        .transform(lambda d: add_start_date(d, src_col=start_date_col, out_col=\"start_date\"))\n",
    "        .transform(lambda d: add_distance_km(d, distance_col=distance_col, out_col=\"distance_km\", decimals=2))\n",
    "        .transform(lambda d: add_average_speed_kmh(d, avg_speed_col=average_speed_col, out_col=\"average_speed_kmh\", decimals=2))\n",
    "        .transform(lambda d: add_pace_min_km(d,\n",
    "                                             elapsed_time_col=elapsed_time_col,\n",
    "                                             distance_col=distance_col,\n",
    "                                             type_col=type_col,\n",
    "                                             out_col=\"pace_min_km\",\n",
    "                                             decimals=2,\n",
    "                                             only_for_run=True,\n",
    "                                             non_run_value=non_run_value_for_pace))\n",
    "        .transform(lambda d: add_pace_min_km_moving_time(d,\n",
    "                                                         moving_time_col=moving_time_col,\n",
    "                                                         distance_col=distance_col,\n",
    "                                                         type_col=type_col,\n",
    "                                                         out_col=\"pace_min_km_moving_time\",\n",
    "                                                         decimals=2,\n",
    "                                                         only_for_run=True,\n",
    "                                                         non_run_value=non_run_value_for_pace))\n",
    "        .transform(lambda d: add_tempo_real(d, seconds_col=moving_time_col, out_col=\"tempo_real\"))\n",
    "        .transform(lambda d: add_pace_min_km_new(d,\n",
    "                                                 moving_time_col=moving_time_col,\n",
    "                                                 distance_col=distance_col,\n",
    "                                                 out_col=\"pace_min_km_new\",\n",
    "                                                 decimals=3))\n",
    "        .transform(lambda d: add_pace_strava(d, pace_min_col=\"pace_min_km_new\", out_col=\"pace_strava\"))\n",
    "        .transform(lambda d: add_dia_semana(d, date_col=\"start_date\", out_col=\"dia_semana\", pattern=\"E\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0982f0f3-09db-4922-9ea5-8f0ad0b0c414",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def upsert_data(microBatchDF, batch):\n",
    "    microBatchDF.createOrReplaceTempView(\"activities_microbatch\")\n",
    "    \n",
    "    sql_query = \"\"\"\n",
    "                MERGE INTO uc_athlete_data.silver.strava_activities A\n",
    "                USING activities_microbatch B\n",
    "                ON A.athlete_id = b.athlete_id\n",
    "                   AND A.ID = B.ID\n",
    "                   AND A.START_DATE = B.START_DATE\n",
    "                WHEN NOT MATCHED THEN INSERT * \n",
    "                \"\"\"  \n",
    "\n",
    "    microBatchDF.sparkSession.sql(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "584c0261-6d2c-4d5b-83d7-b1bdd988d075",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_data(microBatchDF, batch):   \n",
    "    \n",
    "    microBatchDF = dedupe_microbatch(microBatchDF,BUSINESS_KEYS,ORDER_COLS)\n",
    "    print(\"dedup ok \")\n",
    "    microBatchDF = apply_all_silver_calcs(microBatchDF)\n",
    "    print(\"calcs ok \")\n",
    "    df_clean = assert_quality(microBatchDF,rules,reject_table)\n",
    "    print(\"clean ok \")\n",
    "    df_clean = add_silver_ingestion_timestamp(df_clean)   \n",
    "    upsert_data(df_clean, batch)\n",
    "    print(\"upsert ok \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f07cd733-8766-46fb-a5ac-5153b1c3e742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_stream = spark.readStream.table(BRONZE)\n",
    "\n",
    "query = (bronze_stream.writeStream\n",
    "                 .foreachBatch(load_data)\n",
    "                 .option(\"checkpointLocation\", CHECKPOINT)\n",
    "                 .trigger(availableNow=True)\n",
    "                 .start())\n",
    "                 \n",
    "query.awaitTermination()\n",
    "progress = query.lastProgress\n",
    "\n",
    "log = Row(\n",
    "        batchId = progress[\"batchId\"],\n",
    "        inputRows = progress[\"numInputRows\"],\n",
    "        outputRows = progress[\"sink\"][\"numOutputRows\"],\n",
    "        timestamp = progress[\"timestamp\"]\n",
    "        )\n",
    "\n",
    "# print para logs do job\n",
    "print(f\"[Silver] Batch {log.batchId} | In: {log.inputRows} | Out: {log.outputRows} | TS: {log.timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "115169c7-36cf-440c-82c6-7e97c2f09dc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT count(*) as total, reject_reason, date(reject_timestamp) as dt\n",
    "FROM uc_athlete_data.silver_rejects.strava_activities\n",
    "GROUP BY 2,3\n",
    "ORDER BY 3 DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "011d9c1f-2030-4568-bfbb-e03477abebb0",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"start_date_local\":201},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761433331893}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from uc_athlete_data.silver.strava_activities\n",
    "order by ingestion_timestamp desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37eb867e-e35c-4b5d-a308-9fc1dc401fa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from uc_athlete_data.silver_rejects.strava_activities\n",
    "order by reject_timestamp desc"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5512316157703284,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_Stream",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
